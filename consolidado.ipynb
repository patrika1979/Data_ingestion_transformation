{"cells":[{"cell_type":"code","source":["import argparse\nimport snscrape.modules.twitter as sntwitter\n\nfrom pyspark.sql import SparkSession\n\n\ndef create_spark_views(customers_location: str, products_location: str, transactions_location: str):\n    spark.read.format(\"com.crealytics.spark.excel\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").load(location_2017)  .createOrReplaceTempView(\"sales_2017\")\n    \n    spark.read.format(\"com.crealytics.spark.excel\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(location_2018).createOrReplaceTempView(\"sales_2018\")\n        \n    spark.read.format(\"com.crealytics.spark.excel\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(location_2019).createOrReplaceTempView(\"sales_2019\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"216f11ff-42c7-4240-902f-2179ec0e27fc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def run_transformations(location_2017: str, location_2018: str, location_2019: str, date_from, date_to, output_location: str, url:str):\n    create_spark_views(location_2017, location_2018, location_2019)\n    union_dataset()\n    vendas_ano_mes()\n    vendas_marca_linha()\n    vendas_marca_ano_mes()\n    vendas_linha_ano_mes()\n    vendas_linha_dia_ano_mes()\n    get_tweets(date_from, date_to)\n    tweets_max_sales(output_location, url)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6624be64-fa8e-4aae-8d3b-4099bd916f12","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def union_dataset():\n    result = spark.sql(\"\"\"create or replace temp view vendas_consolidadas as \n                            select * from sales_2017 \n                            union all \n                            select * from sales_2018 \n                            union all \n                            select * from sales_2019\"\"\")  \n    return result"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"e7c85cf4-0f90-4727-97d8-64a03e90f137","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def vendas_ano_mes():\n    result = spark.sql(\"\"\"create or replace temp view vendas_ano_mes as select sum(qtd_venda) as valor,  year(to_date(data_venda, \"m/d/yy\")) as ano,  month(to_date(data_venda, \"m/d/yy\")) as mes from vendas_consolidadas group by ano, mes\"\"\")\n    #spark.write.parquet(output_location + \"/vendas_ano_mes\").partitionBy(\"data_venda\")\n    return result "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"d63159ec-df75-4d3d-aea9-601c0d79379b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def vendas_marca_linha():\n    result = spark.sql(\"\"\"create or replace temp view vendas_marca_linha as select sum(qtd_venda) as valor, marca,linha as mes from vendas_consolidadas  group by marca,linha\"\"\")\n    return result"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"aa06bcb9-8c52-426a-b3fd-6c07cf9aaf73","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def vendas_marca_ano_mes():\n    result = spark.sql(\"\"\"create or replace temp view vendas_marca_ano_mes as select sum(qtd_venda) as valor, marca, year(to_date(data_venda, \"m/d/yy\")) as ano,  month(to_date(data_venda, \"m/d/yy\")) as mes from vendas_consolidadas  group by marca,ano,mes\"\"\")\n    return result"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"84818477-de25-415c-a754-1a254bccc976","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def vendas_linha_ano_mes():\n    result = spark.sql(\"\"\"create or replace temp view vendas_linha_ano_mes as select sum(qtd_venda) as valor, linha, year(to_date(data_venda, \"m/d/yy\")) as ano,  month(to_date(data_venda, \"m/d/yy\")) as mes from vendas_consolidadas group by linha,ano,mes\"\"\")\n    return result"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"407746e5-0311-4e9d-922c-b9df8777fa23","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def vendas_linha_dia_ano_mes():\n    result = spark.sql(\"\"\"create or replace temp view vendas_linha_ano_mes_dia as select sum(qtd_venda) as valor, linha, year(to_date(data_venda, \"m/d/yy\")) as ano,  month(to_date(data_venda, \"m/d/yy\")) as mes, day(to_date(data_venda, \"m/d/yy\")) as dia from vendas_consolidadas  where month(to_date(data_venda, \"m/d/yy\"))=12 and year(to_date(data_venda, \"m/d/yy\"))=2019 group by linha,ano,mes, dia order by valor desc limit 1\"\"\")\n    return result"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"1c81ab97-679e-4b42-8068-fbef66aea0f6","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def get_tweets(date_from, date_to):\n    tweets_list2 = []\n\n    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f'#boticÃ¡rio since:{date_from} until:{date_to}').get_items()):\n        if i>500:\n            break\n        tweets_list2.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.lang])\n\n    df_tweets = spark.createDataFrame(tweets_list2,['Datetime', 'Tweet Id', 'Text', 'Username', 'language']).createOrReplaceTempView(\"tweets\")\n    spark.sql(\"\"\"create or replace temp view latest_tweets as select a.*, year(to_date(a.datetime, \"m/d/yy\")) as ano, month(to_date(a.datetime, \"m/d/yy\")) as mes, day(to_date(a.datetime, \"m/d/yy\")) as dia from tweets a where a.language=\"pt\" order by a.datetime desc limit 50\"\"\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"85a9488a-bbd6-4460-9619-2de4a9f6cdb9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["def tweets_max_sales(output_location, url):\n    result = spark.sql(\"\"\"select b.username, text from vendas_linha_ano_mes_dia a join latest_tweets b on a.dia=b.dia and a.mes=b.mes and a.ano=b.ano\"\"\")\n    \n    try:\n        result.coalesce(1).write.format(\"csv\").option(\"sep\",\",\").save(f\"{output_location}/tweets\")\n    except Exception as e:\n        print(e)\n        \n    try:\n        result.write.format(\"jdbc\")\\\n        .option(\"url\", url) \\\n        .option(\"driver\", driver).option(\"dbtable\", \"tweets1\") \\\n        .save()\n    except Exception as e:\n        print(e)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"730c6418-cee3-4fb1-8ce7-20f191d27eb9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["if __name__ == \"__main__\":\n        \n    driver = \"org.mariadb.jdbc.Driver\"\n    database_host = \"35.188.94.247\"\n    database_port = 3306\n    database_name = \"dados\"\n    user_name = \"root\"\n    password = \"root\"\n    url = f\"jdbc:mysql://{database_host}:{database_port}/{database_name}?user={user_name}&password={password}&allowPublicKeyRetrieval=true&useSSL=false\"\n      \n    bucket_input  = \"gs://playground-s-11-65b238af-data\"\n    bucket_output = \"gs://playground-s-11-65b238af-data-output\"\n    location_2017 = f\"{bucket_input}/Base2017.xlsx\"\n    location_2018 = f\"{bucket_input}/Base_2018.xlsx\"\n    location_2019 = f\"{bucket_input}/Base_2019.xlsx\"\n    output_location = f\"{bucket_output}\"\n    date_from = \"2019-12-01\"\n    date_to = \"2019-12-31\"\n\n    run_transformations(location_2017, location_2018, location_2019, date_from, date_to, output_location, url)\n    "],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"f505a76e-9619-4f84-acea-407efd731c42","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["#Test if the data is written in SQL Cloud Database\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"24f13108-4f93-4484-a787-bf762159c6f2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["driver = \"org.mariadb.jdbc.Driver\"\ndatabase_host = \"35.188.94.247\"\ndatabase_port = 3306\ndatabase_name = \"dados\"\nuser_name = \"root\"\npassword = \"root\"\nurl = f\"jdbc:mysql://{database_host}:{database_port}/{database_name}?user={user_name}&password={password}&allowPublicKeyRetrieval=true&useSSL=false\"\ntry:\n    tweets_table.write.format(\"jdbc\")\\\n        .option(\"url\", url) \\\n        .option(\"driver\", driver).option(\"dbtable\", \"tweets\") \\\n         .save()\nexcept Exception as e:\n    print(e)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{},"nuid":"6dfa63ab-d896-4275-b339-b05174787420","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"consolidado","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4,"mostRecentlyExecutedCommandWithImplicitDF":{"commandId":3970538548121292,"dataframes":["_sqldf"]}},"language":"python","widgets":{},"notebookOrigID":887247626900019}},"nbformat":4,"nbformat_minor":0}
